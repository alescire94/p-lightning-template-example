# @package _group_


#embeddings:
#  embedding_dim: 300

sequence_encoder:
  _target_: torch.nn.GRU
  bidirectional: False
  hidden_size: 100
  input_size: 300
  dropout: 0.2
  num_layers: 15
  batch_first: True